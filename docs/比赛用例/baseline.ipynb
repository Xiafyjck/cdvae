{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56311e4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "镜像：flowmm:0612\n",
    "\n",
    "机型：c4_m15_1 * NVIDIA T4\n",
    "\n",
    "本文介绍使用baseline模型进行比赛的提交流程. Baseline模型是DiffCSP模型，该模型没有使用PXRD信息，只是使用晶胞内原子成分预测晶体结构，模型技术细节参考论文：https://arxiv.org/abs/2309.04475\n",
    "\n",
    "模型代码参见https://github.com/jiaor17/DiffCSP\n",
    "\n",
    "这里的baseline 模型直接使用了论文作者提供的mpts_52_csp checkpoint.\n",
    "\n",
    "比赛的A榜数据在数据集PXRD-test-expo(v2)中\n",
    "\n",
    "参赛注意事项\n",
    "后台打分时使用的环境\n",
    "网络：后台打分时不会联网的，因此，notebook中关于下载软件/包的命令都无法执行。请先创建好你需要的环境。\n",
    "环境： 选手提交notebook的时候，右上角可以选择镜像。可以选择baseline notebook 的镜像，也可以自己定义镜像\n",
    "数据: 关于AB榜的数据（晶胞内原子成分，和谱）不需要额外挂载数据集，按照baseline notebook的示例即可。如果你的notebook会用到额外的数据集，也可以自己定义数据集挂载上来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67544758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义路径\n",
    "import os\n",
    "MODEL_PATH = \"/bohr/test-3h1m/v5/DiffCSP\"\n",
    "if os.environ.get('DATA_PATH'):\n",
    "    DATA_PATH = os.environ.get(\"DATA_PATH\")\n",
    "else:\n",
    "    print(\"Baseline运行时，因为无法读取测试集，所以会有此条报错，属于正常现象\")  #Baseline运行时，因为无法读取测试集，所以会有此条报错，属于正常现象\n",
    "    print(\"When the baseline is running, this error message will appear because the test set cannot be read, which is a normal phenomenon.\") #When the baseline is running, this error message will appear because the test set cannot be read, which is a normal phenomenon.\n",
    "# 检查关键路径\n",
    "print(\"MODEL_PATH:\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/baseline\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f00b9c",
   "metadata": {},
   "source": [
    "****使用baseline模型进行预测. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = MODEL_PATH\n",
    "script_name = \"scripts/generate_cif_from_model.py\"\n",
    "ckpt_path = f\"{MODEL_PATH}/mpts_52_ckpt\"\n",
    "command = f\"\"\"\n",
    "cd {project_root} && \\\n",
    "PYTHONPATH={project_root} python scripts/evaluate.py \\\n",
    "--model_path {ckpt_path} \\\n",
    "--dataset mpts_52 \\\n",
    "--output_dir /baseline \\\n",
    "--composition_file_path {DATA_PATH}/composition.json\n",
    "\"\"\"\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780761f3",
   "metadata": {},
   "source": [
    "上面的单元格运行结束之后，在/baseline路径中会产生一个eval_diff.pt 文件。这个文件存储了解析之后的2000个晶体结构. \n",
    "\n",
    "接下来演示如何准备submission.csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pymatgen.core import Structure, Lattice, Element\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "data = torch.load(\"/baseline/eval_diff.pt\", map_location='cpu')\n",
    "frac_coords = data['frac_coords']  # Tensor形状[1, 27820, 3]\n",
    "num_atoms = data['num_atoms']      # Tensor形状[1, 2000]\n",
    "atom_types = data['atom_types']    # Tensor形状[1, 27820]\n",
    "lattices = data['lattices']        # Tensor形状[1, 2000, 3, 3]\n",
    "\n",
    "# 假设输入数据为以下变量\n",
    "# frac_coords: Tensor形状[1, 27820, 3]\n",
    "# num_atoms: Tensor形状[1, 2000]\n",
    "# atom_types: Tensor形状[1, 27820]\n",
    "# lattices: Tensor形状[1, 2000, 3, 3]\n",
    "\n",
    "# 去除批次维度\n",
    "frac_coords = frac_coords.squeeze(0)  # [27820, 3]\n",
    "num_atoms = num_atoms.squeeze(0)      # [2000]\n",
    "atom_types = atom_types.squeeze(0)     # [27820]\n",
    "lattices = lattices.squeeze(0)        # [2000, 3, 3]\n",
    "\n",
    "# 确保张量在CPU上以便转换为numpy\n",
    "frac_coords = frac_coords.cpu()\n",
    "num_atoms = num_atoms.cpu().long()    # 转换为整型\n",
    "atom_types = atom_types.cpu()\n",
    "lattices = lattices.cpu()\n",
    "\n",
    "# 验证原子总数是否匹配\n",
    "total_atoms = num_atoms.sum().item()\n",
    "assert total_atoms == frac_coords.shape[0], \"原子总数不匹配\"\n",
    "assert len(atom_types) == total_atoms, \"原子类型数量不匹配\"\n",
    "\n",
    "# 拆分每个晶体的数据\n",
    "structures = []\n",
    "current_idx = 0\n",
    "for i in range(num_atoms.shape[0]):\n",
    "    n_i = num_atoms[i].item()\n",
    "    # 提取第i个晶体的数据\n",
    "    coords = frac_coords[current_idx:current_idx + n_i].numpy()\n",
    "    types = atom_types[current_idx:current_idx + n_i].numpy().astype(int)\n",
    "    lattice_matrix = lattices[i].numpy()\n",
    "    \n",
    "    # 转换为元素对象列表\n",
    "    species = [Element.from_Z(z) for z in types]\n",
    "    \n",
    "    # 创建Lattice和Structure\n",
    "    lattice = Lattice(lattice_matrix)\n",
    "    structure = Structure(lattice, species, coords)\n",
    "    structures.append(structure)\n",
    "    \n",
    "    current_idx += n_i\n",
    "\n",
    "# 最终的结构列表包含2000个Structure对象\n",
    "print(f\"成功生成{len(structures)}个晶体结构\")\n",
    "\n",
    "\n",
    "# 生成submission文件\n",
    "header = [\"ID\", \"cif\"]\n",
    "rows = []\n",
    "\n",
    "\"\"\"\n",
    "!!!!!!!重要!!!!!!!!!!:\n",
    "比赛区分A,B榜，因此结构的ID的前缀不同，notebook 需要可以判断出结构ID前缀是A还是B, 否则会导致没有分数!!!\n",
    "\"\"\"\n",
    "import json\n",
    "with open(f\"{DATA_PATH}/composition.json\", 'r') as f:\n",
    "    composition_dict = json.load(f)\n",
    "prefix = next(iter(composition_dict))[0]\n",
    "print(prefix)\n",
    "\n",
    "# store cif files and create a list of dictionary for spgroup number and crystal system\n",
    "for i in tqdm(range(len(structures)), desc=\"Generating CIF files\"):\n",
    "    # check if id is a str or numpy.int\n",
    "    ID = f\"{prefix}-{i+1}\"\n",
    "    cif = structures[i].to(fmt=\"cif\")\n",
    "    rows.append([ID, cif])\n",
    "# save header and rows to a csv file\n",
    "df = pd.DataFrame(rows, columns=header)\n",
    "\n",
    "\"\"\"\n",
    "!!!!!!!!!重要!!!!!!!\n",
    "产生的submission.csv 必须在. 目录下，否则没有得分\n",
    "\"\"\"\n",
    "df.to_csv(f\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
